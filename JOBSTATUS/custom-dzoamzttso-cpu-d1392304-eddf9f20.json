{"status":"Succeeded","log":["JOB:custom-dzoamzttso-cpu-d1392304-eddf9f20(TRAINING) status changed:null->Initialized","JOB:custom-dzoamzttso-cpu-d1392304-eddf9f20(TRAINING) status changed:Initialized->Started","JOB:custom-dzoamzttso-cpu-d1392304-eddf9f20(TRAINING) status changed:Started->Running pre train steps","JOB:custom-dzoamzttso-cpu-d1392304-eddf9f20(TRAINING) status changed:Running pre train steps->Started","JOB:custom-dzoamzttso-cpu-d1392304-eddf9f20(TRAINING) status changed:Started->Process started","Model management server:http://192.168.65.2:8080/","Model:dzOAmzttsO","Version:1","Training ID:","Downloading files for training","Python 3.5.2","*   Trying 192.168.65.2...","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current","                                 Dload  Upload   Total   Spent    Left  Speed","","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0* Connected to 192.168.65.2 (192.168.65.2) port 8080 (#0)","> GET //model-management/CUSTOM/model/dzOAmzttsO/resource.zip HTTP/1.1","> Host: 192.168.65.2:8080","> User-Agent: curl/7.47.0","> Accept: */*","> ","< HTTP/1.1 200 ","< Content-Type: application/octet-stream","< Content-Length: 7188191","< Date: Thu, 01 Mar 2018 22:50:46 GMT","< ","{ [4261 bytes data]","","100 7019k  100 7019k    0     0  33.5M      0 --:--:-- --:--:-- --:--:-- 33.6M","* Connection #0 to host 192.168.65.2 left intact","*   Trying 192.168.65.2...","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current","                                 Dload  Upload   Total   Spent    Left  Speed","","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0* Connected to 192.168.65.2 (192.168.65.2) port 8080 (#0)","> GET //model-management/CUSTOM/model/dzOAmzttsO HTTP/1.1","> Host: 192.168.65.2:8080","> User-Agent: curl/7.47.0","> Accept: */*","> ","< HTTP/1.1 200 ","< Content-Type: application/json;charset=UTF-8","< Transfer-Encoding: chunked","< Date: Thu, 01 Mar 2018 22:50:46 GMT","< ","{ [200 bytes data]","","100   194    0   194    0     0  11037      0 --:--:-- --:--:-- --:--:-- 11411","* Connection #0 to host 192.168.65.2 left intact","Unpacking","Archive:  input/model.zip","   creating: resource/","   creating: resource/pipeline/","  inflating: resource/pipeline/tensor_logistic_regression_classifier.py  ","   creating: __MACOSX/","   creating: __MACOSX/resource/","   creating: __MACOSX/resource/pipeline/","  inflating: __MACOSX/resource/pipeline/._tensor_logistic_regression_classifier.py  ","  inflating: resource/pipeline/pipes_np.py  ","  inflating: __MACOSX/resource/pipeline/._pipes_np.py  ","  inflating: resource/pipeline/__init__.py  ","  inflating: __MACOSX/resource/pipeline/.___init__.py  ","   creating: resource/pipeline/__pycache__/","  inflating: resource/pipeline/__pycache__/keras_classifier.cpython-36.pyc  ","  inflating: resource/pipeline/__pycache__/pipe.cpython-36.pyc  ","  inflating: resource/pipeline/__pycache__/pipes_df.cpython-36.pyc  ","  inflating: resource/pipeline/__pycache__/pipeline.cpython-36.pyc  ","  inflating: resource/pipeline/__pycache__/serialization.cpython-36.pyc  ","  inflating: resource/pipeline/__pycache__/__init__.cpython-36.pyc  ","  inflating: resource/pipeline/classifiers.py  ","  inflating: __MACOSX/resource/pipeline/._classifiers.py  ","  inflating: resource/pipeline/pipeline.py  ","  inflating: __MACOSX/resource/pipeline/._pipeline.py  ","  inflating: resource/pipeline/pipes_df.py  ","  inflating: __MACOSX/resource/pipeline/._pipes_df.py  ","  inflating: resource/pipeline/keras_classifier.py  ","  inflating: __MACOSX/resource/pipeline/._keras_classifier.py  ","  inflating: resource/pipeline/explainers.py  ","  inflating: __MACOSX/resource/pipeline/._explainers.py  ","  inflating: resource/pipeline/pipe.py  ","  inflating: __MACOSX/resource/pipeline/._pipe.py  ","  inflating: resource/pipeline/serialization.py  ","  inflating: __MACOSX/resource/pipeline/._serialization.py  ","  inflating: __MACOSX/resource/._pipeline  ","  inflating: resource/.DS_Store      ","  inflating: __MACOSX/resource/._.DS_Store  ","  inflating: resource/requirements.txt  ","  inflating: __MACOSX/resource/._requirements.txt  ","   creating: resource/tests/","  inflating: resource/tests/auxiliar.py  ","   creating: __MACOSX/resource/tests/","  inflating: __MACOSX/resource/tests/._auxiliar.py  "," extracting: resource/tests/__init__.py  ","  inflating: __MACOSX/resource/tests/.___init__.py  ","   creating: resource/tests/test_iterators/","  inflating: resource/tests/test_iterators/test_pickle.py  ","   creating: __MACOSX/resource/tests/test_iterators/","  inflating: __MACOSX/resource/tests/test_iterators/._test_pickle.py  "," extracting: resource/tests/test_iterators/__init__.py  ","  inflating: __MACOSX/resource/tests/test_iterators/.___init__.py  ","  inflating: resource/tests/test_iterators/test_train_test.py  ","  inflating: __MACOSX/resource/tests/test_iterators/._test_train_test.py  ","  inflating: resource/tests/test_iterators/test_csv.py  ","  inflating: __MACOSX/resource/tests/test_iterators/._test_csv.py  ","  inflating: __MACOSX/resource/tests/._test_iterators  ","   creating: resource/tests/test_pipeline/","  inflating: resource/tests/test_pipeline/auxiliar.py  ","   creating: __MACOSX/resource/tests/test_pipeline/","  inflating: __MACOSX/resource/tests/test_pipeline/._auxiliar.py  ","  inflating: resource/tests/test_pipeline/test_explainers.py  ","  inflating: __MACOSX/resource/tests/test_pipeline/._test_explainers.py  "," extracting: resource/tests/test_pipeline/__init__.py  ","  inflating: __MACOSX/resource/tests/test_pipeline/.___init__.py  ","  inflating: resource/tests/test_pipeline/test_pipes_np.py  ","  inflating: __MACOSX/resource/tests/test_pipeline/._test_pipes_np.py  ","  inflating: resource/tests/test_pipeline/test_kerasclassifier.py  ","  inflating: __MACOSX/resource/tests/test_pipeline/._test_kerasclassifier.py  ","  inflating: resource/tests/test_pipeline/test_classifiers.py  ","  inflating: __MACOSX/resource/tests/test_pipeline/._test_classifiers.py  ","  inflating: resource/tests/test_pipeline/test_serialization.py  ","  inflating: __MACOSX/resource/tests/test_pipeline/._test_serialization.py  ","  inflating: resource/tests/test_pipeline/test_batch.py  ","  inflating: __MACOSX/resource/tests/test_pipeline/._test_batch.py  ","  inflating: resource/tests/test_pipeline/test_pipeline.py  ","  inflating: __MACOSX/resource/tests/test_pipeline/._test_pipeline.py  ","  inflating: resource/tests/test_pipeline/test_pipes_df.py  ","  inflating: __MACOSX/resource/tests/test_pipeline/._test_pipes_df.py  ","  inflating: __MACOSX/resource/tests/._test_pipeline  ","   creating: resource/tests/test_generators/"," extracting: resource/tests/test_generators/__init__.py  ","   creating: __MACOSX/resource/tests/test_generators/","  inflating: __MACOSX/resource/tests/test_generators/.___init__.py  ","  inflating: resource/tests/test_generators/test_teradata.py  ","  inflating: __MACOSX/resource/tests/test_generators/._test_teradata.py  ","  inflating: __MACOSX/resource/tests/._test_generators  ","  inflating: __MACOSX/resource/._tests  ","  inflating: resource/README.md      ","  inflating: __MACOSX/resource/._README.md  ","  inflating: resource/setup.py       ","  inflating: __MACOSX/resource/._setup.py  ","   creating: resource/examples/","  inflating: resource/examples/keras_fit_generator_save.py  ","   creating: __MACOSX/resource/examples/","  inflating: __MACOSX/resource/examples/._keras_fit_generator_save.py  "," extracting: resource/examples/__init__.py  ","  inflating: __MACOSX/resource/examples/.___init__.py  ","  inflating: resource/examples/keras_fit_all_data.py  ","  inflating: __MACOSX/resource/examples/._keras_fit_all_data.py  ","  inflating: resource/examples/kaggle_loaded.py  ","  inflating: __MACOSX/resource/examples/._kaggle_loaded.py  ","  inflating: resource/examples/keras_pickle_input_source.py  ","  inflating: __MACOSX/resource/examples/._keras_pickle_input_source.py  ","  inflating: resource/examples/keras_multiple_inputs.py  ","  inflating: __MACOSX/resource/examples/._keras_multiple_inputs.py  ","  inflating: resource/examples/keras_fit_generator.py  ","  inflating: __MACOSX/resource/examples/._keras_fit_generator.py  ","  inflating: __MACOSX/resource/._examples  ","   creating: resource/generators/","  inflating: resource/generators/teradata_generator.py  ","   creating: __MACOSX/resource/generators/","  inflating: __MACOSX/resource/generators/._teradata_generator.py  ","  inflating: __MACOSX/resource/._generators  ","  inflating: resource/pipeline.iml   ","  inflating: __MACOSX/resource/._pipeline.iml  ","   creating: resource/data/","  inflating: resource/data/validation.csv  ","   creating: __MACOSX/resource/data/","  inflating: __MACOSX/resource/data/._validation.csv  ","  inflating: resource/data/training.csv  ","  inflating: __MACOSX/resource/data/._training.csv  ","  inflating: resource/data/.DS_Store  ","  inflating: __MACOSX/resource/data/._.DS_Store  ","   creating: resource/iterators/","  inflating: resource/iterators/dummy_iterator.py  ","   creating: __MACOSX/resource/iterators/","  inflating: __MACOSX/resource/iterators/._dummy_iterator.py  ","  inflating: resource/iterators/train_test.py  ","  inflating: __MACOSX/resource/iterators/._train_test.py  ","  inflating: resource/iterators/__init__.py  ","  inflating: __MACOSX/resource/iterators/.___init__.py  ","   creating: resource/iterators/__pycache__/","  inflating: resource/iterators/__pycache__/sqlalchemy.cpython-36.pyc  ","  inflating: resource/iterators/__pycache__/mysql.cpython-36.pyc  ","  inflating: resource/iterators/__pycache__/train_test.cpython-36.pyc  ","  inflating: resource/iterators/__pycache__/csv.cpython-36.pyc  ","  inflating: resource/iterators/__pycache__/dummy_iterator.cpython-36.pyc  ","  inflating: resource/iterators/__pycache__/pickle.cpython-36.pyc  ","  inflating: resource/iterators/__pycache__/__init__.cpython-36.pyc  ","  inflating: resource/iterators/__pycache__/teradata.cpython-36.pyc  ","  inflating: __MACOSX/resource/iterators/.___pycache__  ","  inflating: resource/iterators/sqlalchemy.py  ","  inflating: __MACOSX/resource/iterators/._sqlalchemy.py  ","  inflating: resource/iterators/csv.py  ","  inflating: __MACOSX/resource/iterators/._csv.py  ","  inflating: resource/iterators/pickle.py  ","  inflating: __MACOSX/resource/iterators/._pickle.py  ","  inflating: resource/iterators/teradata.py  ","  inflating: __MACOSX/resource/iterators/._teradata.py  ","  inflating: resource/iterators/mysql.py  ","  inflating: __MACOSX/resource/iterators/._mysql.py  ","  inflating: __MACOSX/resource/._iterators  ","   creating: resource/.idea/","  inflating: resource/.idea/workspace.xml  ","   creating: __MACOSX/resource/.idea/","  inflating: __MACOSX/resource/.idea/._workspace.xml  ","  inflating: resource/.idea/modules.xml  ","  inflating: __MACOSX/resource/.idea/._modules.xml  ","  inflating: resource/.idea/misc.xml  ","  inflating: __MACOSX/resource/.idea/._misc.xml  ","  inflating: __MACOSX/resource/._.idea  ","  inflating: __MACOSX/._resource     ","Install requirements","Requirement already satisfied: keras in /usr/local/lib/python3.5/dist-packages (from -r ./resource/requirements.txt (line 1))","Requirement already satisfied: tensorflow in /usr/local/lib/python3.5/dist-packages (from -r ./resource/requirements.txt (line 2))","Requirement already satisfied: pandas in /usr/local/lib/python3.5/dist-packages (from -r ./resource/requirements.txt (line 3))","Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.5/dist-packages (from -r ./resource/requirements.txt (line 4))","Requirement already satisfied: sqlalchemy_utils in /usr/local/lib/python3.5/dist-packages (from -r ./resource/requirements.txt (line 5))","Collecting pymysql (from -r ./resource/requirements.txt (line 6))","  Downloading PyMySQL-0.8.0-py2.py3-none-any.whl (83kB)","Collecting cloudpickle (from -r ./resource/requirements.txt (line 7))","  Downloading cloudpickle-0.5.2-py2.py3-none-any.whl","Requirement already satisfied: sklearn in /usr/local/lib/python3.5/dist-packages (from -r ./resource/requirements.txt (line 8))","Requirement already satisfied: h5py in /usr/local/lib/python3.5/dist-packages (from -r ./resource/requirements.txt (line 9))","Requirement already satisfied: teradata in /usr/local/lib/python3.5/dist-packages (from -r ./resource/requirements.txt (line 10))","Collecting lime (from -r ./resource/requirements.txt (line 11))","  Downloading lime-0.1.1.29.tar.gz (260kB)","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.5/dist-packages (from keras->-r ./resource/requirements.txt (line 1))","Requirement already satisfied: pyyaml in /usr/local/lib/python3.5/dist-packages (from keras->-r ./resource/requirements.txt (line 1))","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.5/dist-packages (from keras->-r ./resource/requirements.txt (line 1))","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.5/dist-packages (from keras->-r ./resource/requirements.txt (line 1))","Requirement already satisfied: tensorflow-tensorboard<0.5.0,>=0.4.0rc1 in /usr/local/lib/python3.5/dist-packages (from tensorflow->-r ./resource/requirements.txt (line 2))","Requirement already satisfied: protobuf>=3.3.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow->-r ./resource/requirements.txt (line 2))","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.5/dist-packages (from tensorflow->-r ./resource/requirements.txt (line 2))","Requirement already satisfied: enum34>=1.1.6 in /usr/local/lib/python3.5/dist-packages (from tensorflow->-r ./resource/requirements.txt (line 2))","Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.5/dist-packages (from pandas->-r ./resource/requirements.txt (line 3))","Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.5/dist-packages (from pandas->-r ./resource/requirements.txt (line 3))","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.5/dist-packages (from sklearn->-r ./resource/requirements.txt (line 8))","Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.5/dist-packages (from lime->-r ./resource/requirements.txt (line 11))","Requirement already satisfied: bleach==1.5.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow->-r ./resource/requirements.txt (line 2))","Requirement already satisfied: html5lib==0.9999999 in /usr/local/lib/python3.5/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow->-r ./resource/requirements.txt (line 2))","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.5/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow->-r ./resource/requirements.txt (line 2))","Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.5/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow->-r ./resource/requirements.txt (line 2))","Requirement already satisfied: setuptools in /usr/local/lib/python3.5/dist-packages (from protobuf>=3.3.0->tensorflow->-r ./resource/requirements.txt (line 2))","Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.5/dist-packages (from scikit-image>=0.12->lime->-r ./resource/requirements.txt (line 11))","Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python3.5/dist-packages (from scikit-image>=0.12->lime->-r ./resource/requirements.txt (line 11))","Requirement already satisfied: matplotlib>=1.3.1 in /usr/local/lib/python3.5/dist-packages (from scikit-image>=0.12->lime->-r ./resource/requirements.txt (line 11))","Requirement already satisfied: pillow>=2.1.0 in /usr/local/lib/python3.5/dist-packages (from scikit-image>=0.12->lime->-r ./resource/requirements.txt (line 11))","Requirement already satisfied: decorator>=4.1.0 in /usr/local/lib/python3.5/dist-packages (from networkx>=1.8->scikit-image>=0.12->lime->-r ./resource/requirements.txt (line 11))","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.5/dist-packages (from matplotlib>=1.3.1->scikit-image>=0.12->lime->-r ./resource/requirements.txt (line 11))","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.5/dist-packages (from matplotlib>=1.3.1->scikit-image>=0.12->lime->-r ./resource/requirements.txt (line 11))","Requirement already satisfied: olefile in /usr/local/lib/python3.5/dist-packages (from pillow>=2.1.0->scikit-image>=0.12->lime->-r ./resource/requirements.txt (line 11))","Installing collected packages: pymysql, cloudpickle, lime","  Running setup.py install for lime: started","    Running setup.py install for lime: finished with status 'done'","Successfully installed cloudpickle-0.5.2 lime-0.1.1.29 pymysql-0.8.0","Training model","2018-03-01 22:50:51.577785: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA","{\"status\":200,\"payload\":{\"modelName\":\"dzOAmzttsO\",\"modelType\":\"CUSTOM\",\"entryPoint\":\"resource/examples/keras_fit_generator_save.py\",\"performanceJson\":\"performance.json\",\"outputFolder\":\"output\"}}Epoch 1/2",""," 1/90 [..............................] - ETA: 12s - loss: 0.0029 - mean_absolute_error: 0.0026 - acc: 1.0000","16/90 [====>.........................] - ETA: 0s - loss: 0.0158 - mean_absolute_error: 0.0011 - acc: 0.9990 ","29/90 [========>.....................] - ETA: 0s - loss: 0.0087 - mean_absolute_error: 6.2980e-04 - acc: 0.9995","41/90 [============>.................] - ETA: 0s - loss: 0.0092 - mean_absolute_error: 6.3602e-04 - acc: 0.9994","53/90 [================>.............] - ETA: 0s - loss: 0.0450 - mean_absolute_error: 0.0029 - acc: 0.9972    ","63/90 [====================>.........] - ETA: 0s - loss: 0.0497 - mean_absolute_error: 0.0031 - acc: 0.9969","75/90 [========================>.....] - ETA: 0s - loss: 0.0635 - mean_absolute_error: 0.0040 - acc: 0.9960","90/90 [==============================] - 1s 6ms/step - loss: 0.0682 - mean_absolute_error: 0.0043 - acc: 0.9957","Epoch 2/2",""," 1/90 [..............................] - ETA: 0s - loss: 1.0960e-07 - mean_absolute_error: 0.0000e+00 - acc: 1.0000","13/90 [===>..........................] - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.0042 - acc: 0.9958        ","26/90 [=======>......................] - ETA: 0s - loss: 0.0578 - mean_absolute_error: 0.0036 - acc: 0.9964","39/90 [============>.................] - ETA: 0s - loss: 0.0803 - mean_absolute_error: 0.0050 - acc: 0.9950","54/90 [=================>............] - ETA: 0s - loss: 0.0742 - mean_absolute_error: 0.0046 - acc: 0.9954","66/90 [=====================>........] - ETA: 0s - loss: 0.0683 - mean_absolute_error: 0.0043 - acc: 0.9957","78/90 [=========================>....] - ETA: 0s - loss: 0.0594 - mean_absolute_error: 0.0037 - acc: 0.9963","89/90 [============================>.] - ETA: 0s - loss: 0.0521 - mean_absolute_error: 0.0032 - acc: 0.9968","90/90 [==============================] - 0s 4ms/step - loss: 0.0515 - mean_absolute_error: 0.0032 - acc: 0.9968","Using TensorFlow backend.","{'mae': 0.0020410420890483593, 'loss': 0.030749048282639378, 'acc': 0.99809027777777781}","Saving output","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current","                                 Dload  Upload   Total   Spent    Left  Speed","","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0","100    87    0     0  100    87      0     72  0:00:01  0:00:01 --:--:--    72","100    87    0     0  100    87      0     39  0:00:02  0:00:02 --:--:--    39","100    87    0     0  100    87      0     27  0:00:03  0:00:03 --:--:--    27","100    87    0     0  100    87      0     20  0:00:04  0:00:04 --:--:--    20","100    87    0     0  100    87      0     16  0:00:05  0:00:05 --:--:--    16","100    87    0     0  100    87      0     13  0:00:06  0:00:06 --:--:--     0","100    87    0     0  100    87      0     12  0:00:07  0:00:07 --:--:--     0","100   316    0   229  100    87     29     11  0:00:07  0:00:07 --:--:--    31","100   316    0   229  100    87     29     11  0:00:07  0:00:07 --:--:--    40","Upload performance{\"status\":200,\"payload\":{\"id\":\"1\",\"modelName\":\"dzOAmzttsO\",\"checksum\":\"cpu-d1392304-eddf9f20\",\"parameters\":{},\"performance\":{\"acc\":0.9980902777777778,\"loss\":0.030749048282639378,\"mae\":0.0020410420890483593},\"date\":1519944638597}}","Upload model  adding: output/ (stored 0%)","  adding: output/saved_model.pb (deflated 88%)","  adding: output/variables/ (stored 0%)","  adding: output/variables/variables.data-00000-of-00001 (deflated 12%)","  adding: output/variables/variables.index (deflated 32%)","  adding: output/keras_model.h5 (deflated 36%)","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current","                                 Dload  Upload   Total   Spent    Left  Speed","","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0","100  101k    0     0  100  101k      0   101k  0:00:01  0:00:01 --:--:--  101k","100  101k    0     0  100  101k      0  51836  0:00:02  0:00:02 --:--:-- 51841","100  101k    0     0  100  101k      0  34571  0:00:03  0:00:03 --:--:-- 34584","100  101k    0     0  100  101k      0  25926  0:00:04  0:00:04 --:--:-- 25933","100  101k    0     0  100  101k      0  20741  0:00:05  0:00:05 --:--:-- 20745","100  101k    0     0  100  101k      0  17280  0:00:06  0:00:06 --:--:--     0","100  101k    0     0  100  101k      0  14817  0:00:07  0:00:07 --:--:--     0","100  101k    0    49  100  101k      6  13288  0:00:07  0:00:07 --:--:--     0","100  101k    0    49  100  101k      6  13284  0:00:07  0:00:07 --:--:--     0","{\"status\":200,\"payload\":\"104104 bytes written. \"}","Execution finished","JOB:custom-dzoamzttso-cpu-d1392304-eddf9f20(TRAINING) status changed:Process started->Succeeded","JOB:custom-dzoamzttso-cpu-d1392304-eddf9f20(TRAINING) status changed:Succeeded->Start training","JOB:custom-dzoamzttso-cpu-d1392304-eddf9f20(TRAINING) status changed:Start training->Started","JOB:custom-dzoamzttso-cpu-d1392304-eddf9f20(TRAINING) status changed:Started->Process started","docker: Error response from daemon: Conflict. The container name \"/custom-dzoamzttso-cpu-d1392304-eddf9f20\" is already in use by container \"102784e4694b46f5bff3f6b89f9d24c09a535c8b2167e9357dde91277ec4ebdc\". You have to remove (or rename) that container to be able to reuse that name.","See 'docker run --help'.","JOB:custom-dzoamzttso-cpu-d1392304-eddf9f20(TRAINING) status changed:Process started->Succeeded"],"id":"custom-dzoamzttso-cpu-d1392304-eddf9f20","metadata":{"MODEL_NAME":"dzOAmzttsO","MODEL_VERSION":"1","API_SERVER":"http://192.168.65.2:8080/","TRAINING_ID":"custom-dzoamzttso-cpu-d1392304-eddf9f20","TOKEN":"a3f17b3c-fa62-4f06-bcca-f06faeae92df","token":"a3f17b3c-fa62-4f06-bcca-f06faeae92df"}}