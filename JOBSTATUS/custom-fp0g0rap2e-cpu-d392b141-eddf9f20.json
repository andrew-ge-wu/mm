{"status":"Succeeded","log":["JOB:custom-fp0g0rap2e-cpu-d392b141-eddf9f20(TRAINING) status changed:null->Initialized","JOB:custom-fp0g0rap2e-cpu-d392b141-eddf9f20(TRAINING) status changed:Initialized->Started","JOB:custom-fp0g0rap2e-cpu-d392b141-eddf9f20(TRAINING) status changed:Started->Running pre train steps","JOB:custom-fp0g0rap2e-cpu-d392b141-eddf9f20(TRAINING) status changed:Running pre train steps->Started","JOB:custom-fp0g0rap2e-cpu-d392b141-eddf9f20(TRAINING) status changed:Started->Process started","Model management server:http://192.168.65.2:8080/","Model:FP0g0RAp2e","Version:1","Training ID:","Downloading files for training","Python 3.5.2","*   Trying 192.168.65.2...","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current","                                 Dload  Upload   Total   Spent    Left  Speed","","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0* Connected to 192.168.65.2 (192.168.65.2) port 8080 (#0)","> GET //model-management/CUSTOM/model/FP0g0RAp2e/resource.zip HTTP/1.1","> Host: 192.168.65.2:8080","> User-Agent: curl/7.47.0","> Accept: */*","> ","< HTTP/1.1 200 ","< Content-Type: application/octet-stream","< Content-Length: 7188191","< Date: Thu, 01 Mar 2018 22:36:17 GMT","< ","{ [4261 bytes data]","","100 7019k  100 7019k    0     0  37.6M      0 --:--:-- --:--:-- --:--:-- 37.8M","* Connection #0 to host 192.168.65.2 left intact","*   Trying 192.168.65.2...","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current","                                 Dload  Upload   Total   Spent    Left  Speed","","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0* Connected to 192.168.65.2 (192.168.65.2) port 8080 (#0)","> GET //model-management/CUSTOM/model/FP0g0RAp2e HTTP/1.1","> Host: 192.168.65.2:8080","> User-Agent: curl/7.47.0","> Accept: */*","> ","< HTTP/1.1 200 ","< Content-Type: application/json;charset=UTF-8","< Transfer-Encoding: chunked","< Date: Thu, 01 Mar 2018 22:36:17 GMT","< ","{ [200 bytes data]","","100   194    0   194    0     0   9543      0 --:--:-- --:--:-- --:--:-- 10210","* Connection #0 to host 192.168.65.2 left intact","Unpacking","Archive:  input/model.zip","   creating: resource/","   creating: resource/pipeline/","  inflating: resource/pipeline/tensor_logistic_regression_classifier.py  ","   creating: __MACOSX/","   creating: __MACOSX/resource/","   creating: __MACOSX/resource/pipeline/","  inflating: __MACOSX/resource/pipeline/._tensor_logistic_regression_classifier.py  ","  inflating: resource/pipeline/pipes_np.py  ","  inflating: __MACOSX/resource/pipeline/._pipes_np.py  ","  inflating: resource/pipeline/__init__.py  ","  inflating: __MACOSX/resource/pipeline/.___init__.py  ","   creating: resource/pipeline/__pycache__/","  inflating: resource/pipeline/__pycache__/keras_classifier.cpython-36.pyc  ","  inflating: resource/pipeline/__pycache__/pipe.cpython-36.pyc  ","  inflating: resource/pipeline/__pycache__/pipes_df.cpython-36.pyc  ","  inflating: resource/pipeline/__pycache__/pipeline.cpython-36.pyc  ","  inflating: resource/pipeline/__pycache__/serialization.cpython-36.pyc  ","  inflating: resource/pipeline/__pycache__/__init__.cpython-36.pyc  ","  inflating: resource/pipeline/classifiers.py  ","  inflating: __MACOSX/resource/pipeline/._classifiers.py  ","  inflating: resource/pipeline/pipeline.py  ","  inflating: __MACOSX/resource/pipeline/._pipeline.py  ","  inflating: resource/pipeline/pipes_df.py  ","  inflating: __MACOSX/resource/pipeline/._pipes_df.py  ","  inflating: resource/pipeline/keras_classifier.py  ","  inflating: __MACOSX/resource/pipeline/._keras_classifier.py  ","  inflating: resource/pipeline/explainers.py  ","  inflating: __MACOSX/resource/pipeline/._explainers.py  ","  inflating: resource/pipeline/pipe.py  ","  inflating: __MACOSX/resource/pipeline/._pipe.py  ","  inflating: resource/pipeline/serialization.py  ","  inflating: __MACOSX/resource/pipeline/._serialization.py  ","  inflating: __MACOSX/resource/._pipeline  ","  inflating: resource/.DS_Store      ","  inflating: __MACOSX/resource/._.DS_Store  ","  inflating: resource/requirements.txt  ","  inflating: __MACOSX/resource/._requirements.txt  ","   creating: resource/tests/","  inflating: resource/tests/auxiliar.py  ","   creating: __MACOSX/resource/tests/","  inflating: __MACOSX/resource/tests/._auxiliar.py  "," extracting: resource/tests/__init__.py  ","  inflating: __MACOSX/resource/tests/.___init__.py  ","   creating: resource/tests/test_iterators/","  inflating: resource/tests/test_iterators/test_pickle.py  ","   creating: __MACOSX/resource/tests/test_iterators/","  inflating: __MACOSX/resource/tests/test_iterators/._test_pickle.py  "," extracting: resource/tests/test_iterators/__init__.py  ","  inflating: __MACOSX/resource/tests/test_iterators/.___init__.py  ","  inflating: resource/tests/test_iterators/test_train_test.py  ","  inflating: __MACOSX/resource/tests/test_iterators/._test_train_test.py  ","  inflating: resource/tests/test_iterators/test_csv.py  ","  inflating: __MACOSX/resource/tests/test_iterators/._test_csv.py  ","  inflating: __MACOSX/resource/tests/._test_iterators  ","   creating: resource/tests/test_pipeline/","  inflating: resource/tests/test_pipeline/auxiliar.py  ","   creating: __MACOSX/resource/tests/test_pipeline/","  inflating: __MACOSX/resource/tests/test_pipeline/._auxiliar.py  ","  inflating: resource/tests/test_pipeline/test_explainers.py  ","  inflating: __MACOSX/resource/tests/test_pipeline/._test_explainers.py  "," extracting: resource/tests/test_pipeline/__init__.py  ","  inflating: __MACOSX/resource/tests/test_pipeline/.___init__.py  ","  inflating: resource/tests/test_pipeline/test_pipes_np.py  ","  inflating: __MACOSX/resource/tests/test_pipeline/._test_pipes_np.py  ","  inflating: resource/tests/test_pipeline/test_kerasclassifier.py  ","  inflating: __MACOSX/resource/tests/test_pipeline/._test_kerasclassifier.py  ","  inflating: resource/tests/test_pipeline/test_classifiers.py  ","  inflating: __MACOSX/resource/tests/test_pipeline/._test_classifiers.py  ","  inflating: resource/tests/test_pipeline/test_serialization.py  ","  inflating: __MACOSX/resource/tests/test_pipeline/._test_serialization.py  ","  inflating: resource/tests/test_pipeline/test_batch.py  ","  inflating: __MACOSX/resource/tests/test_pipeline/._test_batch.py  ","  inflating: resource/tests/test_pipeline/test_pipeline.py  ","  inflating: __MACOSX/resource/tests/test_pipeline/._test_pipeline.py  ","  inflating: resource/tests/test_pipeline/test_pipes_df.py  ","  inflating: __MACOSX/resource/tests/test_pipeline/._test_pipes_df.py  ","  inflating: __MACOSX/resource/tests/._test_pipeline  ","   creating: resource/tests/test_generators/"," extracting: resource/tests/test_generators/__init__.py  ","   creating: __MACOSX/resource/tests/test_generators/","  inflating: __MACOSX/resource/tests/test_generators/.___init__.py  ","  inflating: resource/tests/test_generators/test_teradata.py  ","  inflating: __MACOSX/resource/tests/test_generators/._test_teradata.py  ","  inflating: __MACOSX/resource/tests/._test_generators  ","  inflating: __MACOSX/resource/._tests  ","  inflating: resource/README.md      ","  inflating: __MACOSX/resource/._README.md  ","  inflating: resource/setup.py       ","  inflating: __MACOSX/resource/._setup.py  ","   creating: resource/examples/","  inflating: resource/examples/keras_fit_generator_save.py  ","   creating: __MACOSX/resource/examples/","  inflating: __MACOSX/resource/examples/._keras_fit_generator_save.py  "," extracting: resource/examples/__init__.py  ","  inflating: __MACOSX/resource/examples/.___init__.py  ","  inflating: resource/examples/keras_fit_all_data.py  ","  inflating: __MACOSX/resource/examples/._keras_fit_all_data.py  ","  inflating: resource/examples/kaggle_loaded.py  ","  inflating: __MACOSX/resource/examples/._kaggle_loaded.py  ","  inflating: resource/examples/keras_pickle_input_source.py  ","  inflating: __MACOSX/resource/examples/._keras_pickle_input_source.py  ","  inflating: resource/examples/keras_multiple_inputs.py  ","  inflating: __MACOSX/resource/examples/._keras_multiple_inputs.py  ","  inflating: resource/examples/keras_fit_generator.py  ","  inflating: __MACOSX/resource/examples/._keras_fit_generator.py  ","  inflating: __MACOSX/resource/._examples  ","   creating: resource/generators/","  inflating: resource/generators/teradata_generator.py  ","   creating: __MACOSX/resource/generators/","  inflating: __MACOSX/resource/generators/._teradata_generator.py  ","  inflating: __MACOSX/resource/._generators  ","  inflating: resource/pipeline.iml   ","  inflating: __MACOSX/resource/._pipeline.iml  ","   creating: resource/data/","  inflating: resource/data/validation.csv  ","   creating: __MACOSX/resource/data/","  inflating: __MACOSX/resource/data/._validation.csv  ","  inflating: resource/data/training.csv  ","  inflating: __MACOSX/resource/data/._training.csv  ","  inflating: resource/data/.DS_Store  ","  inflating: __MACOSX/resource/data/._.DS_Store  ","   creating: resource/iterators/","  inflating: resource/iterators/dummy_iterator.py  ","   creating: __MACOSX/resource/iterators/","  inflating: __MACOSX/resource/iterators/._dummy_iterator.py  ","  inflating: resource/iterators/train_test.py  ","  inflating: __MACOSX/resource/iterators/._train_test.py  ","  inflating: resource/iterators/__init__.py  ","  inflating: __MACOSX/resource/iterators/.___init__.py  ","   creating: resource/iterators/__pycache__/","  inflating: resource/iterators/__pycache__/sqlalchemy.cpython-36.pyc  ","  inflating: resource/iterators/__pycache__/mysql.cpython-36.pyc  ","  inflating: resource/iterators/__pycache__/train_test.cpython-36.pyc  ","  inflating: resource/iterators/__pycache__/csv.cpython-36.pyc  ","  inflating: resource/iterators/__pycache__/dummy_iterator.cpython-36.pyc  ","  inflating: resource/iterators/__pycache__/pickle.cpython-36.pyc  ","  inflating: resource/iterators/__pycache__/__init__.cpython-36.pyc  ","  inflating: resource/iterators/__pycache__/teradata.cpython-36.pyc  ","  inflating: __MACOSX/resource/iterators/.___pycache__  ","  inflating: resource/iterators/sqlalchemy.py  ","  inflating: __MACOSX/resource/iterators/._sqlalchemy.py  ","  inflating: resource/iterators/csv.py  ","  inflating: __MACOSX/resource/iterators/._csv.py  ","  inflating: resource/iterators/pickle.py  ","  inflating: __MACOSX/resource/iterators/._pickle.py  ","  inflating: resource/iterators/teradata.py  ","  inflating: __MACOSX/resource/iterators/._teradata.py  ","  inflating: resource/iterators/mysql.py  ","  inflating: __MACOSX/resource/iterators/._mysql.py  ","  inflating: __MACOSX/resource/._iterators  ","   creating: resource/.idea/","  inflating: resource/.idea/workspace.xml  ","   creating: __MACOSX/resource/.idea/","  inflating: __MACOSX/resource/.idea/._workspace.xml  ","  inflating: resource/.idea/modules.xml  ","  inflating: __MACOSX/resource/.idea/._modules.xml  ","  inflating: resource/.idea/misc.xml  ","  inflating: __MACOSX/resource/.idea/._misc.xml  ","  inflating: __MACOSX/resource/._.idea  ","  inflating: __MACOSX/._resource     ","Install requirements","Requirement already satisfied: keras in /usr/local/lib/python3.5/dist-packages (from -r ./resource/requirements.txt (line 1))","Requirement already satisfied: tensorflow in /usr/local/lib/python3.5/dist-packages (from -r ./resource/requirements.txt (line 2))","Requirement already satisfied: pandas in /usr/local/lib/python3.5/dist-packages (from -r ./resource/requirements.txt (line 3))","Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.5/dist-packages (from -r ./resource/requirements.txt (line 4))","Requirement already satisfied: sqlalchemy_utils in /usr/local/lib/python3.5/dist-packages (from -r ./resource/requirements.txt (line 5))","Collecting pymysql (from -r ./resource/requirements.txt (line 6))","  Downloading PyMySQL-0.8.0-py2.py3-none-any.whl (83kB)","Collecting cloudpickle (from -r ./resource/requirements.txt (line 7))","  Downloading cloudpickle-0.5.2-py2.py3-none-any.whl","Requirement already satisfied: sklearn in /usr/local/lib/python3.5/dist-packages (from -r ./resource/requirements.txt (line 8))","Requirement already satisfied: h5py in /usr/local/lib/python3.5/dist-packages (from -r ./resource/requirements.txt (line 9))","Requirement already satisfied: teradata in /usr/local/lib/python3.5/dist-packages (from -r ./resource/requirements.txt (line 10))","Collecting lime (from -r ./resource/requirements.txt (line 11))","  Downloading lime-0.1.1.29.tar.gz (260kB)","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.5/dist-packages (from keras->-r ./resource/requirements.txt (line 1))","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.5/dist-packages (from keras->-r ./resource/requirements.txt (line 1))","Requirement already satisfied: pyyaml in /usr/local/lib/python3.5/dist-packages (from keras->-r ./resource/requirements.txt (line 1))","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.5/dist-packages (from keras->-r ./resource/requirements.txt (line 1))","Requirement already satisfied: tensorflow-tensorboard<0.5.0,>=0.4.0rc1 in /usr/local/lib/python3.5/dist-packages (from tensorflow->-r ./resource/requirements.txt (line 2))","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.5/dist-packages (from tensorflow->-r ./resource/requirements.txt (line 2))","Requirement already satisfied: protobuf>=3.3.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow->-r ./resource/requirements.txt (line 2))","Requirement already satisfied: enum34>=1.1.6 in /usr/local/lib/python3.5/dist-packages (from tensorflow->-r ./resource/requirements.txt (line 2))","Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.5/dist-packages (from pandas->-r ./resource/requirements.txt (line 3))","Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.5/dist-packages (from pandas->-r ./resource/requirements.txt (line 3))","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.5/dist-packages (from sklearn->-r ./resource/requirements.txt (line 8))","Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.5/dist-packages (from lime->-r ./resource/requirements.txt (line 11))","Requirement already satisfied: html5lib==0.9999999 in /usr/local/lib/python3.5/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow->-r ./resource/requirements.txt (line 2))","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.5/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow->-r ./resource/requirements.txt (line 2))","Requirement already satisfied: bleach==1.5.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow->-r ./resource/requirements.txt (line 2))","Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.5/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow->-r ./resource/requirements.txt (line 2))","Requirement already satisfied: setuptools in /usr/local/lib/python3.5/dist-packages (from protobuf>=3.3.0->tensorflow->-r ./resource/requirements.txt (line 2))","Requirement already satisfied: matplotlib>=1.3.1 in /usr/local/lib/python3.5/dist-packages (from scikit-image>=0.12->lime->-r ./resource/requirements.txt (line 11))","Requirement already satisfied: pillow>=2.1.0 in /usr/local/lib/python3.5/dist-packages (from scikit-image>=0.12->lime->-r ./resource/requirements.txt (line 11))","Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.5/dist-packages (from scikit-image>=0.12->lime->-r ./resource/requirements.txt (line 11))","Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python3.5/dist-packages (from scikit-image>=0.12->lime->-r ./resource/requirements.txt (line 11))","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.5/dist-packages (from matplotlib>=1.3.1->scikit-image>=0.12->lime->-r ./resource/requirements.txt (line 11))","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.5/dist-packages (from matplotlib>=1.3.1->scikit-image>=0.12->lime->-r ./resource/requirements.txt (line 11))","Requirement already satisfied: olefile in /usr/local/lib/python3.5/dist-packages (from pillow>=2.1.0->scikit-image>=0.12->lime->-r ./resource/requirements.txt (line 11))","Requirement already satisfied: decorator>=4.1.0 in /usr/local/lib/python3.5/dist-packages (from networkx>=1.8->scikit-image>=0.12->lime->-r ./resource/requirements.txt (line 11))","Installing collected packages: pymysql, cloudpickle, lime","  Running setup.py install for lime: started","    Running setup.py install for lime: finished with status 'done'","Successfully installed cloudpickle-0.5.2 lime-0.1.1.29 pymysql-0.8.0","Training model","2018-03-01 22:36:23.341301: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA","{\"status\":200,\"payload\":{\"modelName\":\"FP0g0RAp2e\",\"modelType\":\"CUSTOM\",\"entryPoint\":\"resource/examples/keras_fit_generator_save.py\",\"performanceJson\":\"performance.json\",\"outputFolder\":\"output\"}}Epoch 1/2",""," 1/90 [..............................] - ETA: 12s - loss: 7.8542 - mean_absolute_error: 0.8369 - acc: 0.1484","12/90 [===>..........................] - ETA: 1s - loss: 14.3384 - mean_absolute_error: 0.9390 - acc: 0.0592","19/90 [=====>........................] - ETA: 0s - loss: 11.5114 - mean_absolute_error: 0.7568 - acc: 0.2422","32/90 [=========>....................] - ETA: 0s - loss: 6.9019 - mean_absolute_error: 0.4537 - acc: 0.5457 ","41/90 [============>.................] - ETA: 0s - loss: 5.3899 - mean_absolute_error: 0.3543 - acc: 0.6452","47/90 [==============>...............] - ETA: 0s - loss: 4.7019 - mean_absolute_error: 0.3091 - acc: 0.6905","56/90 [=================>............] - ETA: 0s - loss: 3.9954 - mean_absolute_error: 0.2625 - acc: 0.7372","65/90 [====================>.........] - ETA: 0s - loss: 3.4460 - mean_absolute_error: 0.2264 - acc: 0.7733","72/90 [=======================>......] - ETA: 0s - loss: 3.1249 - mean_absolute_error: 0.2052 - acc: 0.7945","76/90 [========================>.....] - ETA: 0s - loss: 2.9654 - mean_absolute_error: 0.1947 - acc: 0.8050","82/90 [==========================>...] - ETA: 0s - loss: 2.7515 - mean_absolute_error: 0.1807 - acc: 0.8191","86/90 [===========================>..] - ETA: 0s - loss: 2.6351 - mean_absolute_error: 0.1730 - acc: 0.8268","90/90 [==============================] - 1s 9ms/step - loss: 2.5194 - mean_absolute_error: 0.1654 - acc: 0.8344","Epoch 2/2",""," 1/90 [..............................] - ETA: 1s - loss: 1.0960e-07 - mean_absolute_error: 0.0000e+00 - acc: 1.0000"," 6/90 [=>............................] - ETA: 1s - loss: 0.1252 - mean_absolute_error: 0.0078 - acc: 0.9922        ","13/90 [===>..........................] - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.0042 - acc: 0.9958","20/90 [=====>........................] - ETA: 0s - loss: 0.0438 - mean_absolute_error: 0.0027 - acc: 0.9973","26/90 [=======>......................] - ETA: 0s - loss: 0.0578 - mean_absolute_error: 0.0036 - acc: 0.9964","31/90 [=========>....................] - ETA: 0s - loss: 0.0687 - mean_absolute_error: 0.0043 - acc: 0.9957","36/90 [===========>..................] - ETA: 0s - loss: 0.0835 - mean_absolute_error: 0.0052 - acc: 0.9948","45/90 [==============>...............] - ETA: 0s - loss: 0.0751 - mean_absolute_error: 0.0047 - acc: 0.9953","52/90 [================>.............] - ETA: 0s - loss: 0.0771 - mean_absolute_error: 0.0048 - acc: 0.9952","57/90 [==================>...........] - ETA: 0s - loss: 0.0791 - mean_absolute_error: 0.0049 - acc: 0.9951","66/90 [=====================>........] - ETA: 0s - loss: 0.0683 - mean_absolute_error: 0.0043 - acc: 0.9957","71/90 [======================>.......] - ETA: 0s - loss: 0.0653 - mean_absolute_error: 0.0041 - acc: 0.9959","77/90 [========================>.....] - ETA: 0s - loss: 0.0602 - mean_absolute_error: 0.0038 - acc: 0.9962","87/90 [============================>.] - ETA: 0s - loss: 0.0533 - mean_absolute_error: 0.0033 - acc: 0.9967","90/90 [==============================] - 1s 8ms/step - loss: 0.0515 - mean_absolute_error: 0.0032 - acc: 0.9968","Using TensorFlow backend.","{'acc': 0.99809027777777781, 'loss': 0.030785629857268126, 'mae': 0.0020747333971990484}","Saving output","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current","                                 Dload  Upload   Total   Spent    Left  Speed","","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0","100    87    0     0  100    87      0     72  0:00:01  0:00:01 --:--:--    72","100    87    0     0  100    87      0     39  0:00:02  0:00:02 --:--:--    39","100    87    0     0  100    87      0     27  0:00:03  0:00:03 --:--:--    27","100    87    0     0  100    87      0     20  0:00:04  0:00:04 --:--:--    20","100    87    0     0  100    87      0     16  0:00:05  0:00:05 --:--:--    16","100    87    0     0  100    87      0     13  0:00:06  0:00:06 --:--:--     0","100   316    0   229  100    87     32     12  0:00:07  0:00:07 --:--:--    29","100   316    0   229  100    87     32     12  0:00:07  0:00:07 --:--:--    36","Upload performance{\"status\":200,\"payload\":{\"id\":\"1\",\"modelName\":\"FP0g0RAp2e\",\"checksum\":\"cpu-d392b141-eddf9f20\",\"parameters\":{},\"performance\":{\"acc\":0.9980902777777778,\"loss\":0.030785629857268126,\"mae\":0.0020747333971990484},\"date\":1519943771542}}","Upload model  adding: output/ (stored 0%)","  adding: output/saved_model.pb (deflated 88%)","  adding: output/variables/ (stored 0%)","  adding: output/variables/variables.data-00000-of-00001 (deflated 10%)","  adding: output/variables/variables.index (deflated 32%)","  adding: output/keras_model.h5 (deflated 35%)","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current","                                 Dload  Upload   Total   Spent    Left  Speed","","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0","100  104k    0     0  100  104k      0   103k  0:00:01  0:00:01 --:--:--  103k","100  104k    0     0  100  104k      0  53258  0:00:02  0:00:02 --:--:-- 53272","100  104k    0     0  100  104k      0  35515  0:00:03  0:00:03 --:--:-- 35526","100  104k    0     0  100  104k      0  26637  0:00:04  0:00:04 --:--:-- 26642","100  104k    0     0  100  104k      0  21313  0:00:05  0:00:05 --:--:-- 21317","100  104k    0     0  100  104k      0  17756  0:00:06  0:00:06 --:--:--     0","100  104k    0     0  100  104k      0  15212  0:00:07  0:00:07 --:--:--     0","100  104k    0    49  100  104k      6  14806  0:00:07  0:00:07 --:--:--     0","{\"status\":200,\"payload\":\"106556 bytes written. \"}","Execution finished","JOB:custom-fp0g0rap2e-cpu-d392b141-eddf9f20(TRAINING) status changed:Process started->Succeeded","JOB:custom-fp0g0rap2e-cpu-d392b141-eddf9f20(TRAINING) status changed:Succeeded->Start training","JOB:custom-fp0g0rap2e-cpu-d392b141-eddf9f20(TRAINING) status changed:Start training->Started","JOB:custom-fp0g0rap2e-cpu-d392b141-eddf9f20(TRAINING) status changed:Started->Process started","docker: Error response from daemon: Conflict. The container name \"/custom-fp0g0rap2e-cpu-d392b141-eddf9f20\" is already in use by container \"31cc44b89ab1ff73c0b8d1f6ba78c766fb323a9f9eeebd67945e88eb90046c38\". You have to remove (or rename) that container to be able to reuse that name.","See 'docker run --help'.","JOB:custom-fp0g0rap2e-cpu-d392b141-eddf9f20(TRAINING) status changed:Process started->Succeeded"],"id":"custom-fp0g0rap2e-cpu-d392b141-eddf9f20","metadata":{"MODEL_NAME":"FP0g0RAp2e","MODEL_VERSION":"1","API_SERVER":"http://192.168.65.2:8080/","TRAINING_ID":"custom-fp0g0rap2e-cpu-d392b141-eddf9f20","TOKEN":"7b0c0770-236c-408f-ad18-5f3353a7f96d","token":"7b0c0770-236c-408f-ad18-5f3353a7f96d"}}