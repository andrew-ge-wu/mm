{"status":"Succeeded","log":["JOB:custom-khufy87b5q-cpu-419f7f55-eddf9f20(TRAINING) status changed:null->Initialized","JOB:custom-khufy87b5q-cpu-419f7f55-eddf9f20(TRAINING) status changed:Initialized->Started","JOB:custom-khufy87b5q-cpu-419f7f55-eddf9f20(TRAINING) status changed:Started->Running pre train steps","JOB:custom-khufy87b5q-cpu-419f7f55-eddf9f20(TRAINING) status changed:Running pre train steps->Started","JOB:custom-khufy87b5q-cpu-419f7f55-eddf9f20(TRAINING) status changed:Started->Process started","Model management server:http://192.168.65.2:8080/","Model:khUfy87B5q","Version:1","Training ID:","Downloading files for training","Python 3.5.2","*   Trying 192.168.65.2...","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current","                                 Dload  Upload   Total   Spent    Left  Speed","","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0* Connected to 192.168.65.2 (192.168.65.2) port 8080 (#0)","> GET //model-management/CUSTOM/model/khUfy87B5q/resource.zip HTTP/1.1","> Host: 192.168.65.2:8080","> User-Agent: curl/7.47.0","> Accept: */*","> ","< HTTP/1.1 200 ","< Content-Type: application/octet-stream","< Content-Length: 153030","< Date: Thu, 01 Mar 2018 16:00:30 GMT","< ","{ [4262 bytes data]","","100  149k  100  149k    0     0  4426k      0 --:--:-- --:--:-- --:--:-- 4528k","* Connection #0 to host 192.168.65.2 left intact","*   Trying 192.168.65.2...","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current","                                 Dload  Upload   Total   Spent    Left  Speed","","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0* Connected to 192.168.65.2 (192.168.65.2) port 8080 (#0)","> GET //model-management/CUSTOM/model/khUfy87B5q HTTP/1.1","> Host: 192.168.65.2:8080","> User-Agent: curl/7.47.0","> Accept: */*","> ","< HTTP/1.1 200 ","< Content-Type: application/json;charset=UTF-8","< Transfer-Encoding: chunked","< Date: Thu, 01 Mar 2018 16:00:30 GMT","< ","{ [189 bytes data]","","100   183    0   183    0     0   8541      0 --:--:-- --:--:-- --:--:--  8714","* Connection #0 to host 192.168.65.2 left intact","Unpacking","Archive:  input/model.zip","   creating: model/","  inflating: model/model.iml         ","   creating: model/database/","  inflating: model/database/db_pandas_to_sql.pyc  ","  inflating: model/database/__init__.py  ","  inflating: model/database/__init__.pyc  ","  inflating: model/database/db_pandas_to_sql.py  ","  inflating: model/database/db_write_line_by_line.py  ","   creating: model/pipeline/","  inflating: model/pipeline/tensor_logistic_regression_classifier.py  ","  inflating: model/pipeline/pipes_np.py  ","  inflating: model/pipeline/keras_classifier.pyc  ","  inflating: model/pipeline/lime.py  ","  inflating: model/pipeline/io.py    ","  inflating: model/pipeline/__init__.py  ","   creating: model/pipeline/__pycache__/","  inflating: model/pipeline/__pycache__/keras_classifier.cpython-36.pyc  ","  inflating: model/pipeline/__pycache__/pipes_np.cpython-36.pyc  ","  inflating: model/pipeline/__pycache__/pipe.cpython-36.pyc  ","  inflating: model/pipeline/__pycache__/pipeline.cpython-36.pyc  ","  inflating: model/pipeline/__pycache__/io.cpython-36.pyc  ","  inflating: model/pipeline/__pycache__/__init__.cpython-36.pyc  ","  inflating: model/pipeline/io.pyc   ","  inflating: model/pipeline/README.md  ","  inflating: model/pipeline/pipeline.pyc  ","  inflating: model/pipeline/pipeline.py  ","  inflating: model/pipeline/__init__.pyc  ","  inflating: model/pipeline/pipes_df.py  ","  inflating: model/pipeline/keras_classifier.py  ","  inflating: model/pipeline/explanatory_pipeline.py  ","  inflating: model/pipeline/pipe.py  ","  inflating: model/pipeline/logistic_regression_classifier.py  ","  inflating: model/pipeline/convolutional_pipeline.py  ","  inflating: model/pipeline/local_explainer.py  ","  inflating: model/pipeline/pipe.pyc  ","   creating: model/docker/","   creating: model/docker/tfserving/","  inflating: model/docker/tfserving/Dockerfile  ","   creating: model/docker/trainer/","  inflating: model/docker/trainer/Dockerfile  ","  inflating: model/.DS_Store         ","   creating: __MACOSX/","   creating: __MACOSX/model/","  inflating: __MACOSX/model/._.DS_Store  ","  inflating: model/requirements.txt  ","   creating: model/test/","   creating: model/test/variables/","   creating: model/end_to_end/","  inflating: model/end_to_end/train_pipeline.py  ","  inflating: model/end_to_end/use_pipeline.py  "," extracting: model/end_to_end/__init__.py  ","  inflating: model/end_to_end/README.md  ","  inflating: model/end_to_end/define_pipeline.py  ","  inflating: model/end_to_end/explain_pipeline.py  ","  inflating: model/credentials.py    ","   creating: model/input/","  inflating: model/compare_losses.ipynb  ","   creating: model/tests/","  inflating: model/tests/auxiliar.py  ","  inflating: model/tests/test_conv_pipeline.py  ","  inflating: model/tests/test_logReg.py  "," extracting: model/tests/__init__.py  ","  inflating: model/tests/test_end_to_end.py  ","   creating: model/tests/test_iterators/","  inflating: model/tests/test_iterators/test_pickle.py  "," extracting: model/tests/test_iterators/__init__.py  ","  inflating: model/tests/test_iterators/test_csv.py  ","   creating: model/tests/test_pipeline/","  inflating: model/tests/test_pipeline/auxiliar.py  "," extracting: model/tests/test_pipeline/__init__.py  ","  inflating: model/tests/test_pipeline/test_io.py  ","  inflating: model/tests/test_pipeline/test_pipes_np.py  ","  inflating: model/tests/test_pipeline/test_kerasclassifier.py  ","  inflating: model/tests/test_pipeline/test_explanation.py  ","  inflating: model/tests/test_pipeline/test_batch.py  ","  inflating: model/tests/test_pipeline/test_pipeline.py  ","  inflating: model/tests/test_pipeline/test_pipes_df.py  ","  inflating: model/tests/test_tensor_logreg_pipeline.py  ","  inflating: model/tests/test_models.py  ","  inflating: model/tests/test_loss.py  ","   creating: model/tests/test_generators/"," extracting: model/tests/test_generators/__init__.py  ","  inflating: model/tests/test_generators/test_e_fraud.py  ","  inflating: model/generate_bust_out.py  ","   creating: model/models/","  inflating: model/models/lstm_bust_out_synthetic.py  ","  inflating: model/models/__init__.py  ","  inflating: model/models/dense_bust_out_synthetic.py  ","  inflating: model/models/README.md  ","   creating: model/__pycache__/","  inflating: model/__pycache__/credentials.cpython-36.pyc  ","  inflating: model/credentials.pyc   ","  inflating: model/README.md         ","  inflating: model/loss.py           ","  inflating: model/setup.py          ","  inflating: model/populate_server_db.py  ","   creating: model/examples/"," extracting: model/examples/__init__.py  ","  inflating: model/examples/keras_fit_all_data.py  ","  inflating: model/examples/kaggle_loaded.py  ","  inflating: model/examples/keras_pickle_input_source.py  ","  inflating: model/examples/keras_multiple_inputs.py  ","  inflating: model/examples/keras_fit_generator.py  ","   creating: model/scripts/","  inflating: model/scripts/tfserving-entry.sh  ","  inflating: model/scripts/build-trainer-image.sh  ","  inflating: model/scripts/trainer-entry.sh  ","  inflating: model/scripts/build-tfserving-image.sh  ","  inflating: model/scripts/train.py  ","   creating: model/generators/","  inflating: model/generators/e_fraud.py  "," extracting: model/generators/__init__.py  ","  inflating: model/generators/README.md  ","   creating: model/generators/bust-out/","  inflating: model/generators/bust-out/gencc.py  ","  inflating: model/generators/bust-out/bust_out.py  ","  inflating: model/generators/bust-out/generate_other_tables.py  ","  inflating: model/generators/bust-out/transaction_values.py  ","   creating: model/generators/random/","  inflating: model/generators/random/synthetic_anomalies.py  ","  inflating: model/generators/random/__init__.py  ","  inflating: model/generators/random/synth_cc  ","  inflating: model/generators/random/README.md  ","  inflating: model/generators/random/synth_template  ","   creating: model/data/"," extracting: model/data/.gitkeep     ","  inflating: model/data/__init__.py  ","   creating: model/data/__pycache__/","  inflating: model/data/__pycache__/__init__.cpython-36.pyc  ","   creating: model/iterators/","  inflating: model/iterators/dummy_iterator.py  ","  inflating: model/iterators/__init__.py  ","   creating: model/iterators/__pycache__/","  inflating: model/iterators/__pycache__/sqlalchemy.cpython-36.pyc  ","  inflating: model/iterators/__pycache__/mysql.cpython-36.pyc  ","  inflating: model/iterators/__pycache__/dummy_iterator.cpython-36.pyc  ","  inflating: model/iterators/__pycache__/__init__.cpython-36.pyc  ","  inflating: model/iterators/__pycache__/teradata.cpython-36.pyc  ","  inflating: model/iterators/README.md  ","  inflating: model/iterators/sqlalchemy.py  ","  inflating: model/iterators/csv.py  ","  inflating: model/iterators/pickle.py  ","  inflating: model/iterators/teradata.py  ","  inflating: model/iterators/mysql.py  ","Install requirements","","Usage:   ","  /usr/bin/python3 -m pip install [options] <requirement specifier> [package-index-options] ...","  /usr/bin/python3 -m pip install [options] -r <requirements file> [package-index-options] ...","  /usr/bin/python3 -m pip install [options] [-e] <vcs project url> ...","  /usr/bin/python3 -m pip install [options] [-e] <local project path> ...","  /usr/bin/python3 -m pip install [options] <archive url/path> ...","","-r option requires 1 argument","Training model","{\"status\":200,\"payload\":{\"modelName\":\"khUfy87B5q\",\"modelType\":\"CUSTOM\",\"entryPoint\":\"model/end_to_end/train_pipeline.py\",\"performanceJson\":\"performance.json\",\"outputFolder\":\"output\"}}Unable to locate script specified:model/end_to_end/train_pipeline.py","+","Execution finished","JOB:custom-khufy87b5q-cpu-419f7f55-eddf9f20(TRAINING) status changed:Process started->Succeeded","JOB:custom-khufy87b5q-cpu-419f7f55-eddf9f20(TRAINING) status changed:Succeeded->Start training","JOB:custom-khufy87b5q-cpu-419f7f55-eddf9f20(TRAINING) status changed:Start training->Started","JOB:custom-khufy87b5q-cpu-419f7f55-eddf9f20(TRAINING) status changed:Started->Process started","Model management server:http://192.168.65.2:8080/","Model:khUfy87B5q","Version:1","Training ID:","Downloading files for training","Python 3.5.2","*   Trying 192.168.65.2...","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current","                                 Dload  Upload   Total   Spent    Left  Speed","","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0* Connected to 192.168.65.2 (192.168.65.2) port 8080 (#0)","> GET //model-management/CUSTOM/model/khUfy87B5q/resource.zip HTTP/1.1","> Host: 192.168.65.2:8080","> User-Agent: curl/7.47.0","> Accept: */*","> ","< HTTP/1.1 200 ","< Content-Type: application/octet-stream","< Content-Length: 153030","< Date: Thu, 01 Mar 2018 16:00:33 GMT","< ","{ [2802 bytes data]","","100  149k  100  149k    0     0  14.0M      0 --:--:-- --:--:-- --:--:-- 16.2M","* Connection #0 to host 192.168.65.2 left intact","*   Trying 192.168.65.2...","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current","                                 Dload  Upload   Total   Spent    Left  Speed","","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0* Connected to 192.168.65.2 (192.168.65.2) port 8080 (#0)","> GET //model-management/CUSTOM/model/khUfy87B5q HTTP/1.1","> Host: 192.168.65.2:8080","> User-Agent: curl/7.47.0","> Accept: */*","> ","< HTTP/1.1 200 ","< Content-Type: application/json;charset=UTF-8","< Transfer-Encoding: chunked","< Date: Thu, 01 Mar 2018 16:00:33 GMT","< ","{ [189 bytes data]","","100   183    0   183    0     0  29024      0 --:--:-- --:--:-- --:--:-- 30500","* Connection #0 to host 192.168.65.2 left intact","Unpacking","Archive:  input/model.zip","   creating: model/","  inflating: model/model.iml         ","   creating: model/database/","  inflating: model/database/db_pandas_to_sql.pyc  ","  inflating: model/database/__init__.py  ","  inflating: model/database/__init__.pyc  ","  inflating: model/database/db_pandas_to_sql.py  ","  inflating: model/database/db_write_line_by_line.py  ","   creating: model/pipeline/","  inflating: model/pipeline/tensor_logistic_regression_classifier.py  ","  inflating: model/pipeline/pipes_np.py  ","  inflating: model/pipeline/keras_classifier.pyc  ","  inflating: model/pipeline/lime.py  ","  inflating: model/pipeline/io.py    ","  inflating: model/pipeline/__init__.py  ","   creating: model/pipeline/__pycache__/","  inflating: model/pipeline/__pycache__/keras_classifier.cpython-36.pyc  ","  inflating: model/pipeline/__pycache__/pipes_np.cpython-36.pyc  ","  inflating: model/pipeline/__pycache__/pipe.cpython-36.pyc  ","  inflating: model/pipeline/__pycache__/pipeline.cpython-36.pyc  ","  inflating: model/pipeline/__pycache__/io.cpython-36.pyc  ","  inflating: model/pipeline/__pycache__/__init__.cpython-36.pyc  ","  inflating: model/pipeline/io.pyc   ","  inflating: model/pipeline/README.md  ","  inflating: model/pipeline/pipeline.pyc  ","  inflating: model/pipeline/pipeline.py  ","  inflating: model/pipeline/__init__.pyc  ","  inflating: model/pipeline/pipes_df.py  ","  inflating: model/pipeline/keras_classifier.py  ","  inflating: model/pipeline/explanatory_pipeline.py  ","  inflating: model/pipeline/pipe.py  ","  inflating: model/pipeline/logistic_regression_classifier.py  ","  inflating: model/pipeline/convolutional_pipeline.py  ","  inflating: model/pipeline/local_explainer.py  ","  inflating: model/pipeline/pipe.pyc  ","   creating: model/docker/","   creating: model/docker/tfserving/","  inflating: model/docker/tfserving/Dockerfile  ","   creating: model/docker/trainer/","  inflating: model/docker/trainer/Dockerfile  ","  inflating: model/.DS_Store         ","   creating: __MACOSX/","   creating: __MACOSX/model/","  inflating: __MACOSX/model/._.DS_Store  ","  inflating: model/requirements.txt  ","   creating: model/test/","   creating: model/test/variables/","   creating: model/end_to_end/","  inflating: model/end_to_end/train_pipeline.py  ","  inflating: model/end_to_end/use_pipeline.py  "," extracting: model/end_to_end/__init__.py  ","  inflating: model/end_to_end/README.md  ","  inflating: model/end_to_end/define_pipeline.py  ","  inflating: model/end_to_end/explain_pipeline.py  ","  inflating: model/credentials.py    ","   creating: model/input/","  inflating: model/compare_losses.ipynb  ","   creating: model/tests/","  inflating: model/tests/auxiliar.py  ","  inflating: model/tests/test_conv_pipeline.py  ","  inflating: model/tests/test_logReg.py  "," extracting: model/tests/__init__.py  ","  inflating: model/tests/test_end_to_end.py  ","   creating: model/tests/test_iterators/","  inflating: model/tests/test_iterators/test_pickle.py  "," extracting: model/tests/test_iterators/__init__.py  ","  inflating: model/tests/test_iterators/test_csv.py  ","   creating: model/tests/test_pipeline/","  inflating: model/tests/test_pipeline/auxiliar.py  "," extracting: model/tests/test_pipeline/__init__.py  ","  inflating: model/tests/test_pipeline/test_io.py  ","  inflating: model/tests/test_pipeline/test_pipes_np.py  ","  inflating: model/tests/test_pipeline/test_kerasclassifier.py  ","  inflating: model/tests/test_pipeline/test_explanation.py  ","  inflating: model/tests/test_pipeline/test_batch.py  ","  inflating: model/tests/test_pipeline/test_pipeline.py  ","  inflating: model/tests/test_pipeline/test_pipes_df.py  ","  inflating: model/tests/test_tensor_logreg_pipeline.py  ","  inflating: model/tests/test_models.py  ","  inflating: model/tests/test_loss.py  ","   creating: model/tests/test_generators/"," extracting: model/tests/test_generators/__init__.py  ","  inflating: model/tests/test_generators/test_e_fraud.py  ","  inflating: model/generate_bust_out.py  ","   creating: model/models/","  inflating: model/models/lstm_bust_out_synthetic.py  ","  inflating: model/models/__init__.py  ","  inflating: model/models/dense_bust_out_synthetic.py  ","  inflating: model/models/README.md  ","   creating: model/__pycache__/","  inflating: model/__pycache__/credentials.cpython-36.pyc  ","  inflating: model/credentials.pyc   ","  inflating: model/README.md         ","  inflating: model/loss.py           ","  inflating: model/setup.py          ","  inflating: model/populate_server_db.py  ","   creating: model/examples/"," extracting: model/examples/__init__.py  ","  inflating: model/examples/keras_fit_all_data.py  ","  inflating: model/examples/kaggle_loaded.py  ","  inflating: model/examples/keras_pickle_input_source.py  ","  inflating: model/examples/keras_multiple_inputs.py  ","  inflating: model/examples/keras_fit_generator.py  ","   creating: model/scripts/","  inflating: model/scripts/tfserving-entry.sh  ","  inflating: model/scripts/build-trainer-image.sh  ","  inflating: model/scripts/trainer-entry.sh  ","  inflating: model/scripts/build-tfserving-image.sh  ","  inflating: model/scripts/train.py  ","   creating: model/generators/","  inflating: model/generators/e_fraud.py  "," extracting: model/generators/__init__.py  ","  inflating: model/generators/README.md  ","   creating: model/generators/bust-out/","  inflating: model/generators/bust-out/gencc.py  ","  inflating: model/generators/bust-out/bust_out.py  ","  inflating: model/generators/bust-out/generate_other_tables.py  ","  inflating: model/generators/bust-out/transaction_values.py  ","   creating: model/generators/random/","  inflating: model/generators/random/synthetic_anomalies.py  ","  inflating: model/generators/random/__init__.py  ","  inflating: model/generators/random/synth_cc  ","  inflating: model/generators/random/README.md  ","  inflating: model/generators/random/synth_template  ","   creating: model/data/"," extracting: model/data/.gitkeep     ","  inflating: model/data/__init__.py  ","   creating: model/data/__pycache__/","  inflating: model/data/__pycache__/__init__.cpython-36.pyc  ","   creating: model/iterators/","  inflating: model/iterators/dummy_iterator.py  ","  inflating: model/iterators/__init__.py  ","   creating: model/iterators/__pycache__/","  inflating: model/iterators/__pycache__/sqlalchemy.cpython-36.pyc  ","  inflating: model/iterators/__pycache__/mysql.cpython-36.pyc  ","  inflating: model/iterators/__pycache__/dummy_iterator.cpython-36.pyc  ","  inflating: model/iterators/__pycache__/__init__.cpython-36.pyc  ","  inflating: model/iterators/__pycache__/teradata.cpython-36.pyc  ","  inflating: model/iterators/README.md  ","  inflating: model/iterators/sqlalchemy.py  ","  inflating: model/iterators/csv.py  ","  inflating: model/iterators/pickle.py  ","  inflating: model/iterators/teradata.py  ","  inflating: model/iterators/mysql.py  ","Install requirements","","Usage:   ","  /usr/bin/python3 -m pip install [options] <requirement specifier> [package-index-options] ...","  /usr/bin/python3 -m pip install [options] -r <requirements file> [package-index-options] ...","  /usr/bin/python3 -m pip install [options] [-e] <vcs project url> ...","  /usr/bin/python3 -m pip install [options] [-e] <local project path> ...","  /usr/bin/python3 -m pip install [options] <archive url/path> ...","","-r option requires 1 argument","JOB:custom-khufy87b5q-cpu-419f7f55-eddf9f20(TRAINING) status changed:Process started->Succeeded","Training model"],"id":"custom-khufy87b5q-cpu-419f7f55-eddf9f20","metadata":{"MODEL_NAME":"khUfy87B5q","MODEL_VERSION":"1","API_SERVER":"http://192.168.65.2:8080/","TRAINING_ID":"custom-khufy87b5q-cpu-419f7f55-eddf9f20","TOKEN":"e68a0e3b-9619-496d-8f2f-9376ea4dd7cd","token":"e68a0e3b-9619-496d-8f2f-9376ea4dd7cd"}}