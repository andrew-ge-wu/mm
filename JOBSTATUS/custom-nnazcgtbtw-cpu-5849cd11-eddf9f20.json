{"status":"Succeeded","log":["JOB:custom-nnazcgtbtw-cpu-5849cd11-eddf9f20(TRAINING) status changed:null->Initialized","JOB:custom-nnazcgtbtw-cpu-5849cd11-eddf9f20(TRAINING) status changed:Initialized->Started","JOB:custom-nnazcgtbtw-cpu-5849cd11-eddf9f20(TRAINING) status changed:Started->Running pre train steps","JOB:custom-nnazcgtbtw-cpu-5849cd11-eddf9f20(TRAINING) status changed:Running pre train steps->Started","JOB:custom-nnazcgtbtw-cpu-5849cd11-eddf9f20(TRAINING) status changed:Started->Process started","Model management server:http://192.168.65.2:8080/","Model:NNazCgtbTw","Version:1","Training ID:","Downloading files for training","Python 3.5.2","*   Trying 192.168.65.2...","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current","                                 Dload  Upload   Total   Spent    Left  Speed","","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0* Connected to 192.168.65.2 (192.168.65.2) port 8080 (#0)","> GET //model-management/CUSTOM/model/NNazCgtbTw/resource.zip HTTP/1.1","> Host: 192.168.65.2:8080","> User-Agent: curl/7.47.0","> Accept: */*","> ","< HTTP/1.1 200 ","< Content-Type: application/octet-stream","< Content-Length: 7188191","< Date: Thu, 01 Mar 2018 22:33:14 GMT","< ","{ [4261 bytes data]","","100 7019k  100 7019k    0     0  23.2M      0 --:--:-- --:--:-- --:--:-- 23.3M","* Connection #0 to host 192.168.65.2 left intact","*   Trying 192.168.65.2...","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current","                                 Dload  Upload   Total   Spent    Left  Speed","","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0* Connected to 192.168.65.2 (192.168.65.2) port 8080 (#0)","> GET //model-management/CUSTOM/model/NNazCgtbTw HTTP/1.1","> Host: 192.168.65.2:8080","> User-Agent: curl/7.47.0","> Accept: */*","> ","< HTTP/1.1 200 ","< Content-Type: application/json;charset=UTF-8","< Transfer-Encoding: chunked","< Date: Thu, 01 Mar 2018 22:33:15 GMT","< ","{ [200 bytes data]","","100   194    0   194    0     0  20583      0 --:--:-- --:--:-- --:--:-- 21555","* Connection #0 to host 192.168.65.2 left intact","Unpacking","Archive:  input/model.zip","   creating: resource/","   creating: resource/pipeline/","  inflating: resource/pipeline/tensor_logistic_regression_classifier.py  ","   creating: __MACOSX/","   creating: __MACOSX/resource/","   creating: __MACOSX/resource/pipeline/","  inflating: __MACOSX/resource/pipeline/._tensor_logistic_regression_classifier.py  ","  inflating: resource/pipeline/pipes_np.py  ","  inflating: __MACOSX/resource/pipeline/._pipes_np.py  ","  inflating: resource/pipeline/__init__.py  ","  inflating: __MACOSX/resource/pipeline/.___init__.py  ","   creating: resource/pipeline/__pycache__/","  inflating: resource/pipeline/__pycache__/keras_classifier.cpython-36.pyc  ","  inflating: resource/pipeline/__pycache__/pipe.cpython-36.pyc  ","  inflating: resource/pipeline/__pycache__/pipes_df.cpython-36.pyc  ","  inflating: resource/pipeline/__pycache__/pipeline.cpython-36.pyc  ","  inflating: resource/pipeline/__pycache__/serialization.cpython-36.pyc  ","  inflating: resource/pipeline/__pycache__/__init__.cpython-36.pyc  ","  inflating: resource/pipeline/classifiers.py  ","  inflating: __MACOSX/resource/pipeline/._classifiers.py  ","  inflating: resource/pipeline/pipeline.py  ","  inflating: __MACOSX/resource/pipeline/._pipeline.py  ","  inflating: resource/pipeline/pipes_df.py  ","  inflating: __MACOSX/resource/pipeline/._pipes_df.py  ","  inflating: resource/pipeline/keras_classifier.py  ","  inflating: __MACOSX/resource/pipeline/._keras_classifier.py  ","  inflating: resource/pipeline/explainers.py  ","  inflating: __MACOSX/resource/pipeline/._explainers.py  ","  inflating: resource/pipeline/pipe.py  ","  inflating: __MACOSX/resource/pipeline/._pipe.py  ","  inflating: resource/pipeline/serialization.py  ","  inflating: __MACOSX/resource/pipeline/._serialization.py  ","  inflating: __MACOSX/resource/._pipeline  ","  inflating: resource/.DS_Store      ","  inflating: __MACOSX/resource/._.DS_Store  ","  inflating: resource/requirements.txt  ","  inflating: __MACOSX/resource/._requirements.txt  ","   creating: resource/tests/","  inflating: resource/tests/auxiliar.py  ","   creating: __MACOSX/resource/tests/","  inflating: __MACOSX/resource/tests/._auxiliar.py  "," extracting: resource/tests/__init__.py  ","  inflating: __MACOSX/resource/tests/.___init__.py  ","   creating: resource/tests/test_iterators/","  inflating: resource/tests/test_iterators/test_pickle.py  ","   creating: __MACOSX/resource/tests/test_iterators/","  inflating: __MACOSX/resource/tests/test_iterators/._test_pickle.py  "," extracting: resource/tests/test_iterators/__init__.py  ","  inflating: __MACOSX/resource/tests/test_iterators/.___init__.py  ","  inflating: resource/tests/test_iterators/test_train_test.py  ","  inflating: __MACOSX/resource/tests/test_iterators/._test_train_test.py  ","  inflating: resource/tests/test_iterators/test_csv.py  ","  inflating: __MACOSX/resource/tests/test_iterators/._test_csv.py  ","  inflating: __MACOSX/resource/tests/._test_iterators  ","   creating: resource/tests/test_pipeline/","  inflating: resource/tests/test_pipeline/auxiliar.py  ","   creating: __MACOSX/resource/tests/test_pipeline/","  inflating: __MACOSX/resource/tests/test_pipeline/._auxiliar.py  ","  inflating: resource/tests/test_pipeline/test_explainers.py  ","  inflating: __MACOSX/resource/tests/test_pipeline/._test_explainers.py  "," extracting: resource/tests/test_pipeline/__init__.py  ","  inflating: __MACOSX/resource/tests/test_pipeline/.___init__.py  ","  inflating: resource/tests/test_pipeline/test_pipes_np.py  ","  inflating: __MACOSX/resource/tests/test_pipeline/._test_pipes_np.py  ","  inflating: resource/tests/test_pipeline/test_kerasclassifier.py  ","  inflating: __MACOSX/resource/tests/test_pipeline/._test_kerasclassifier.py  ","  inflating: resource/tests/test_pipeline/test_classifiers.py  ","  inflating: __MACOSX/resource/tests/test_pipeline/._test_classifiers.py  ","  inflating: resource/tests/test_pipeline/test_serialization.py  ","  inflating: __MACOSX/resource/tests/test_pipeline/._test_serialization.py  ","  inflating: resource/tests/test_pipeline/test_batch.py  ","  inflating: __MACOSX/resource/tests/test_pipeline/._test_batch.py  ","  inflating: resource/tests/test_pipeline/test_pipeline.py  ","  inflating: __MACOSX/resource/tests/test_pipeline/._test_pipeline.py  ","  inflating: resource/tests/test_pipeline/test_pipes_df.py  ","  inflating: __MACOSX/resource/tests/test_pipeline/._test_pipes_df.py  ","  inflating: __MACOSX/resource/tests/._test_pipeline  ","   creating: resource/tests/test_generators/"," extracting: resource/tests/test_generators/__init__.py  ","   creating: __MACOSX/resource/tests/test_generators/","  inflating: __MACOSX/resource/tests/test_generators/.___init__.py  ","  inflating: resource/tests/test_generators/test_teradata.py  ","  inflating: __MACOSX/resource/tests/test_generators/._test_teradata.py  ","  inflating: __MACOSX/resource/tests/._test_generators  ","  inflating: __MACOSX/resource/._tests  ","  inflating: resource/README.md      ","  inflating: __MACOSX/resource/._README.md  ","  inflating: resource/setup.py       ","  inflating: __MACOSX/resource/._setup.py  ","   creating: resource/examples/","  inflating: resource/examples/keras_fit_generator_save.py  ","   creating: __MACOSX/resource/examples/","  inflating: __MACOSX/resource/examples/._keras_fit_generator_save.py  "," extracting: resource/examples/__init__.py  ","  inflating: __MACOSX/resource/examples/.___init__.py  ","  inflating: resource/examples/keras_fit_all_data.py  ","  inflating: __MACOSX/resource/examples/._keras_fit_all_data.py  ","  inflating: resource/examples/kaggle_loaded.py  ","  inflating: __MACOSX/resource/examples/._kaggle_loaded.py  ","  inflating: resource/examples/keras_pickle_input_source.py  ","  inflating: __MACOSX/resource/examples/._keras_pickle_input_source.py  ","  inflating: resource/examples/keras_multiple_inputs.py  ","  inflating: __MACOSX/resource/examples/._keras_multiple_inputs.py  ","  inflating: resource/examples/keras_fit_generator.py  ","  inflating: __MACOSX/resource/examples/._keras_fit_generator.py  ","  inflating: __MACOSX/resource/._examples  ","   creating: resource/generators/","  inflating: resource/generators/teradata_generator.py  ","   creating: __MACOSX/resource/generators/","  inflating: __MACOSX/resource/generators/._teradata_generator.py  ","  inflating: __MACOSX/resource/._generators  ","  inflating: resource/pipeline.iml   ","  inflating: __MACOSX/resource/._pipeline.iml  ","   creating: resource/data/","  inflating: resource/data/validation.csv  ","   creating: __MACOSX/resource/data/","  inflating: __MACOSX/resource/data/._validation.csv  ","  inflating: resource/data/training.csv  ","  inflating: __MACOSX/resource/data/._training.csv  ","  inflating: resource/data/.DS_Store  ","  inflating: __MACOSX/resource/data/._.DS_Store  ","   creating: resource/iterators/","  inflating: resource/iterators/dummy_iterator.py  ","   creating: __MACOSX/resource/iterators/","  inflating: __MACOSX/resource/iterators/._dummy_iterator.py  ","  inflating: resource/iterators/train_test.py  ","  inflating: __MACOSX/resource/iterators/._train_test.py  ","  inflating: resource/iterators/__init__.py  ","  inflating: __MACOSX/resource/iterators/.___init__.py  ","   creating: resource/iterators/__pycache__/","  inflating: resource/iterators/__pycache__/sqlalchemy.cpython-36.pyc  ","  inflating: resource/iterators/__pycache__/mysql.cpython-36.pyc  ","  inflating: resource/iterators/__pycache__/train_test.cpython-36.pyc  ","  inflating: resource/iterators/__pycache__/csv.cpython-36.pyc  ","  inflating: resource/iterators/__pycache__/dummy_iterator.cpython-36.pyc  ","  inflating: resource/iterators/__pycache__/pickle.cpython-36.pyc  ","  inflating: resource/iterators/__pycache__/__init__.cpython-36.pyc  ","  inflating: resource/iterators/__pycache__/teradata.cpython-36.pyc  ","  inflating: __MACOSX/resource/iterators/.___pycache__  ","  inflating: resource/iterators/sqlalchemy.py  ","  inflating: __MACOSX/resource/iterators/._sqlalchemy.py  ","  inflating: resource/iterators/csv.py  ","  inflating: __MACOSX/resource/iterators/._csv.py  ","  inflating: resource/iterators/pickle.py  ","  inflating: __MACOSX/resource/iterators/._pickle.py  ","  inflating: resource/iterators/teradata.py  ","  inflating: __MACOSX/resource/iterators/._teradata.py  ","  inflating: resource/iterators/mysql.py  ","  inflating: __MACOSX/resource/iterators/._mysql.py  ","  inflating: __MACOSX/resource/._iterators  ","   creating: resource/.idea/","  inflating: resource/.idea/workspace.xml  ","   creating: __MACOSX/resource/.idea/","  inflating: __MACOSX/resource/.idea/._workspace.xml  ","  inflating: resource/.idea/modules.xml  ","  inflating: __MACOSX/resource/.idea/._modules.xml  ","  inflating: resource/.idea/misc.xml  ","  inflating: __MACOSX/resource/.idea/._misc.xml  ","  inflating: __MACOSX/resource/._.idea  ","  inflating: __MACOSX/._resource     ","Install requirements","Requirement already satisfied: keras in /usr/local/lib/python3.5/dist-packages (from -r ./resource/requirements.txt (line 1))","Requirement already satisfied: tensorflow in /usr/local/lib/python3.5/dist-packages (from -r ./resource/requirements.txt (line 2))","Requirement already satisfied: pandas in /usr/local/lib/python3.5/dist-packages (from -r ./resource/requirements.txt (line 3))","Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.5/dist-packages (from -r ./resource/requirements.txt (line 4))","Requirement already satisfied: sqlalchemy_utils in /usr/local/lib/python3.5/dist-packages (from -r ./resource/requirements.txt (line 5))","Collecting pymysql (from -r ./resource/requirements.txt (line 6))","  Downloading PyMySQL-0.8.0-py2.py3-none-any.whl (83kB)","Collecting cloudpickle (from -r ./resource/requirements.txt (line 7))","  Downloading cloudpickle-0.5.2-py2.py3-none-any.whl","Requirement already satisfied: sklearn in /usr/local/lib/python3.5/dist-packages (from -r ./resource/requirements.txt (line 8))","Requirement already satisfied: h5py in /usr/local/lib/python3.5/dist-packages (from -r ./resource/requirements.txt (line 9))","Requirement already satisfied: teradata in /usr/local/lib/python3.5/dist-packages (from -r ./resource/requirements.txt (line 10))","Collecting lime (from -r ./resource/requirements.txt (line 11))","  Downloading lime-0.1.1.29.tar.gz (260kB)","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.5/dist-packages (from keras->-r ./resource/requirements.txt (line 1))","Requirement already satisfied: pyyaml in /usr/local/lib/python3.5/dist-packages (from keras->-r ./resource/requirements.txt (line 1))","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.5/dist-packages (from keras->-r ./resource/requirements.txt (line 1))","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.5/dist-packages (from keras->-r ./resource/requirements.txt (line 1))","Requirement already satisfied: protobuf>=3.3.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow->-r ./resource/requirements.txt (line 2))","Requirement already satisfied: enum34>=1.1.6 in /usr/local/lib/python3.5/dist-packages (from tensorflow->-r ./resource/requirements.txt (line 2))","Requirement already satisfied: tensorflow-tensorboard<0.5.0,>=0.4.0rc1 in /usr/local/lib/python3.5/dist-packages (from tensorflow->-r ./resource/requirements.txt (line 2))","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.5/dist-packages (from tensorflow->-r ./resource/requirements.txt (line 2))","Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.5/dist-packages (from pandas->-r ./resource/requirements.txt (line 3))","Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.5/dist-packages (from pandas->-r ./resource/requirements.txt (line 3))","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.5/dist-packages (from sklearn->-r ./resource/requirements.txt (line 8))","Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.5/dist-packages (from lime->-r ./resource/requirements.txt (line 11))","Requirement already satisfied: setuptools in /usr/local/lib/python3.5/dist-packages (from protobuf>=3.3.0->tensorflow->-r ./resource/requirements.txt (line 2))","Requirement already satisfied: bleach==1.5.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow->-r ./resource/requirements.txt (line 2))","Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.5/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow->-r ./resource/requirements.txt (line 2))","Requirement already satisfied: html5lib==0.9999999 in /usr/local/lib/python3.5/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow->-r ./resource/requirements.txt (line 2))","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.5/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow->-r ./resource/requirements.txt (line 2))","Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python3.5/dist-packages (from scikit-image>=0.12->lime->-r ./resource/requirements.txt (line 11))","Requirement already satisfied: pillow>=2.1.0 in /usr/local/lib/python3.5/dist-packages (from scikit-image>=0.12->lime->-r ./resource/requirements.txt (line 11))","Requirement already satisfied: matplotlib>=1.3.1 in /usr/local/lib/python3.5/dist-packages (from scikit-image>=0.12->lime->-r ./resource/requirements.txt (line 11))","Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.5/dist-packages (from scikit-image>=0.12->lime->-r ./resource/requirements.txt (line 11))","Requirement already satisfied: decorator>=4.1.0 in /usr/local/lib/python3.5/dist-packages (from networkx>=1.8->scikit-image>=0.12->lime->-r ./resource/requirements.txt (line 11))","Requirement already satisfied: olefile in /usr/local/lib/python3.5/dist-packages (from pillow>=2.1.0->scikit-image>=0.12->lime->-r ./resource/requirements.txt (line 11))","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.5/dist-packages (from matplotlib>=1.3.1->scikit-image>=0.12->lime->-r ./resource/requirements.txt (line 11))","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.5/dist-packages (from matplotlib>=1.3.1->scikit-image>=0.12->lime->-r ./resource/requirements.txt (line 11))","Installing collected packages: pymysql, cloudpickle, lime","  Running setup.py install for lime: started","    Running setup.py install for lime: finished with status 'done'","Successfully installed cloudpickle-0.5.2 lime-0.1.1.29 pymysql-0.8.0","Training model","2018-03-01 22:33:20.150215: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA","{\"status\":200,\"payload\":{\"modelName\":\"NNazCgtbTw\",\"modelType\":\"CUSTOM\",\"entryPoint\":\"resource/examples/keras_fit_generator_save.py\",\"performanceJson\":\"performance.json\",\"outputFolder\":\"output\"}}Epoch 1/2",""," 1/90 [..............................] - ETA: 16s - loss: 0.0166 - mean_absolute_error: 0.0127 - acc: 0.9922","14/90 [===>..........................] - ETA: 1s - loss: 0.0191 - mean_absolute_error: 0.0020 - acc: 0.9983 ","25/90 [=======>......................] - ETA: 0s - loss: 0.0107 - mean_absolute_error: 0.0011 - acc: 0.9991","30/90 [=========>....................] - ETA: 0s - loss: 0.0089 - mean_absolute_error: 9.4277e-04 - acc: 0.9992","36/90 [===========>..................] - ETA: 0s - loss: 0.0074 - mean_absolute_error: 7.8564e-04 - acc: 0.9993","41/90 [============>.................] - ETA: 0s - loss: 0.0096 - mean_absolute_error: 8.8038e-04 - acc: 0.9992","47/90 [==============>...............] - ETA: 0s - loss: 0.0083 - mean_absolute_error: 7.6799e-04 - acc: 0.9993","52/90 [================>.............] - ETA: 0s - loss: 0.0364 - mean_absolute_error: 0.0025 - acc: 0.9976    ","57/90 [==================>...........] - ETA: 0s - loss: 0.0552 - mean_absolute_error: 0.0036 - acc: 0.9964","61/90 [===================>..........] - ETA: 0s - loss: 0.0516 - mean_absolute_error: 0.0034 - acc: 0.9967","66/90 [=====================>........] - ETA: 0s - loss: 0.0534 - mean_absolute_error: 0.0035 - acc: 0.9966","73/90 [=======================>......] - ETA: 0s - loss: 0.0620 - mean_absolute_error: 0.0040 - acc: 0.9960","80/90 [=========================>....] - ETA: 0s - loss: 0.0613 - mean_absolute_error: 0.0040 - acc: 0.9961","84/90 [===========================>..] - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.0043 - acc: 0.9957","89/90 [============================>.] - ETA: 0s - loss: 0.0691 - mean_absolute_error: 0.0044 - acc: 0.9956","90/90 [==============================] - 1s 12ms/step - loss: 0.0684 - mean_absolute_error: 0.0044 - acc: 0.9957","Epoch 2/2",""," 1/90 [..............................] - ETA: 0s - loss: 1.0960e-07 - mean_absolute_error: 0.0000e+00 - acc: 1.0000"," 3/90 [>.............................] - ETA: 1s - loss: 0.1252 - mean_absolute_error: 0.0078 - acc: 0.9922        "," 6/90 [=>............................] - ETA: 1s - loss: 0.1252 - mean_absolute_error: 0.0078 - acc: 0.9922"," 8/90 [=>............................] - ETA: 1s - loss: 0.1096 - mean_absolute_error: 0.0068 - acc: 0.9932"," 9/90 [==>...........................] - ETA: 2s - loss: 0.0974 - mean_absolute_error: 0.0061 - acc: 0.9939","13/90 [===>..........................] - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.0042 - acc: 0.9958","16/90 [====>.........................] - ETA: 1s - loss: 0.0548 - mean_absolute_error: 0.0034 - acc: 0.9966","18/90 [=====>........................] - ETA: 1s - loss: 0.0487 - mean_absolute_error: 0.0030 - acc: 0.9970","21/90 [======>.......................] - ETA: 1s - loss: 0.0596 - mean_absolute_error: 0.0037 - acc: 0.9963","23/90 [======>.......................] - ETA: 1s - loss: 0.0653 - mean_absolute_error: 0.0041 - acc: 0.9959","28/90 [========>.....................] - ETA: 1s - loss: 0.0537 - mean_absolute_error: 0.0033 - acc: 0.9967","33/90 [==========>...................] - ETA: 1s - loss: 0.0797 - mean_absolute_error: 0.0050 - acc: 0.9950","37/90 [===========>..................] - ETA: 1s - loss: 0.0812 - mean_absolute_error: 0.0051 - acc: 0.9949","43/90 [=============>................] - ETA: 0s - loss: 0.0786 - mean_absolute_error: 0.0049 - acc: 0.9951","46/90 [==============>...............] - ETA: 0s - loss: 0.0817 - mean_absolute_error: 0.0051 - acc: 0.9949","52/90 [================>.............] - ETA: 0s - loss: 0.0771 - mean_absolute_error: 0.0048 - acc: 0.9952","55/90 [=================>............] - ETA: 0s - loss: 0.0774 - mean_absolute_error: 0.0048 - acc: 0.9952","61/90 [===================>..........] - ETA: 0s - loss: 0.0739 - mean_absolute_error: 0.0046 - acc: 0.9954","66/90 [=====================>........] - ETA: 0s - loss: 0.0683 - mean_absolute_error: 0.0043 - acc: 0.9957","71/90 [======================>.......] - ETA: 0s - loss: 0.0653 - mean_absolute_error: 0.0041 - acc: 0.9959","78/90 [=========================>....] - ETA: 0s - loss: 0.0594 - mean_absolute_error: 0.0037 - acc: 0.9963","85/90 [===========================>..] - ETA: 0s - loss: 0.0545 - mean_absolute_error: 0.0034 - acc: 0.9966","90/90 [==============================] - 1s 15ms/step - loss: 0.0515 - mean_absolute_error: 0.0032 - acc: 0.9968","Using TensorFlow backend.","{'loss': 0.031486687799231403, 'acc': 0.99809027777777781, 'mae': 0.0026361281259192869}","Saving output","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current","                                 Dload  Upload   Total   Spent    Left  Speed","","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0","100    84    0     0  100    84      0     69  0:00:01  0:00:01 --:--:--    69","100    84    0     0  100    84      0     38  0:00:02  0:00:02 --:--:--    38","100    84    0     0  100    84      0     26  0:00:03  0:00:03 --:--:--    26","100    84    0     0  100    84      0     19  0:00:04  0:00:04 --:--:--    19","100    84    0     0  100    84      0     16  0:00:05  0:00:05 --:--:--    16","100    84    0     0  100    84      0     13  0:00:06  0:00:06 --:--:--     0","100   310    0   226  100    84     33     12  0:00:07  0:00:06  0:00:01    31","100   310    0   226  100    84     33     12  0:00:07  0:00:06  0:00:01    40","Upload performance{\"status\":200,\"payload\":{\"id\":\"1\",\"modelName\":\"NNazCgtbTw\",\"checksum\":\"cpu-5849cd11-eddf9f20\",\"parameters\":{},\"performance\":{\"acc\":0.9980902777777778,\"loss\":0.0314866877992314,\"mae\":0.002636128125919287},\"date\":1519943587593}}","Upload model  adding: output/ (stored 0%)","  adding: output/saved_model.pb (deflated 88%)","  adding: output/variables/ (stored 0%)","  adding: output/variables/variables.data-00000-of-00001 (deflated 13%)","  adding: output/variables/variables.index (deflated 32%)","  adding: output/keras_model.h5 (deflated 37%)","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current","                                 Dload  Upload   Total   Spent    Left  Speed","","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0","100  101k    0     0  100  101k      0   100k  0:00:01  0:00:01 --:--:--  100k","100  101k    0     0  100  101k      0  51693  0:00:02  0:00:02 --:--:-- 51719","100  101k    0     0  100  101k      0  34434  0:00:03  0:00:03 --:--:-- 34439","100  101k    0     0  100  101k      0  25835  0:00:04  0:00:04 --:--:-- 25840","100  101k    0     0  100  101k      0  20668  0:00:05  0:00:05 --:--:-- 20669","100  101k    0    49  100  101k      8  17930  0:00:05  0:00:05 --:--:--     0","{\"status\":200,\"payload\":\"103393 bytes written. \"}","Execution finished","JOB:custom-nnazcgtbtw-cpu-5849cd11-eddf9f20(TRAINING) status changed:Process started->Succeeded","JOB:custom-nnazcgtbtw-cpu-5849cd11-eddf9f20(TRAINING) status changed:Succeeded->Start training","JOB:custom-nnazcgtbtw-cpu-5849cd11-eddf9f20(TRAINING) status changed:Start training->Started","JOB:custom-nnazcgtbtw-cpu-5849cd11-eddf9f20(TRAINING) status changed:Started->Process started","docker: Error response from daemon: Conflict. The container name \"/custom-nnazcgtbtw-cpu-5849cd11-eddf9f20\" is already in use by container \"409fc95d20994ea26b765d7e2ab111634b326db73a7cbfdf8976f1d70d1aa6e5\". You have to remove (or rename) that container to be able to reuse that name.","See 'docker run --help'.","JOB:custom-nnazcgtbtw-cpu-5849cd11-eddf9f20(TRAINING) status changed:Process started->Succeeded"],"id":"custom-nnazcgtbtw-cpu-5849cd11-eddf9f20","metadata":{"MODEL_NAME":"NNazCgtbTw","MODEL_VERSION":"1","API_SERVER":"http://192.168.65.2:8080/","TRAINING_ID":"custom-nnazcgtbtw-cpu-5849cd11-eddf9f20","TOKEN":"082aefa5-1887-4c70-813d-e9ebccc89dc4","token":"082aefa5-1887-4c70-813d-e9ebccc89dc4"}}